{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rYPj3njI0Pif"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/Total-RD/pymgrid/\n",
      "  Cloning https://github.com/Total-RD/pymgrid/ to /tmp/pip-req-build-id267u0v\n",
      "  Running command git clone -q https://github.com/Total-RD/pymgrid/ /tmp/pip-req-build-id267u0v\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from pymgrid==0.1.0) (2.25.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from pymgrid==0.1.0) (1.1.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pymgrid==0.1.0) (1.18.5)\n",
      "Requirement already satisfied: cvxpy in /opt/conda/lib/python3.7/site-packages (from pymgrid==0.1.0) (1.1.11)\n",
      "Requirement already satisfied: statsmodels in /opt/conda/lib/python3.7/site-packages (from pymgrid==0.1.0) (0.11.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from pymgrid==0.1.0) (3.2.1)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.7/site-packages (from pymgrid==0.1.0) (4.11.0)\n",
      "Requirement already satisfied: cufflinks in /opt/conda/lib/python3.7/site-packages (from pymgrid==0.1.0) (0.17.3)\n",
      "Requirement already satisfied: gym in /opt/conda/lib/python3.7/site-packages (from pymgrid==0.1.0) (0.18.0)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in /opt/conda/lib/python3.7/site-packages (from cufflinks->pymgrid==0.1.0) (7.5.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from cufflinks->pymgrid==0.1.0) (1.15.0)\n",
      "Requirement already satisfied: colorlover>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from cufflinks->pymgrid==0.1.0) (0.3.0)\n",
      "Requirement already satisfied: setuptools>=34.4.1 in /opt/conda/lib/python3.7/site-packages (from cufflinks->pymgrid==0.1.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: ipython>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from cufflinks->pymgrid==0.1.0) (7.14.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.3.0->cufflinks->pymgrid==0.1.0) (4.3.3)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.3.0->cufflinks->pymgrid==0.1.0) (0.17.2)\n",
      "Requirement already satisfied: pexpect in /opt/conda/lib/python3.7/site-packages (from ipython>=5.3.0->cufflinks->pymgrid==0.1.0) (4.8.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=5.3.0->cufflinks->pymgrid==0.1.0) (2.8.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.3.0->cufflinks->pymgrid==0.1.0) (3.0.8)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=5.3.0->cufflinks->pymgrid==0.1.0) (0.7.5)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=5.3.0->cufflinks->pymgrid==0.1.0) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=5.3.0->cufflinks->pymgrid==0.1.0) (4.4.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (3.5.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (5.1.2)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (5.5.0)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (6.1.7)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (6.1)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.10->ipython>=5.3.0->cufflinks->pymgrid==0.1.0) (0.7.1)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (3.2.0)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (4.7.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (20.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (0.17.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->pymgrid==0.1.0) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->pymgrid==0.1.0) (2021.1)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /opt/conda/lib/python3.7/site-packages (from plotly->pymgrid==0.1.0) (1.3.3)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->cufflinks->pymgrid==0.1.0) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.7/site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (6.0.3)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (0.9.2)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (6.0.7)\n",
      "Requirement already satisfied: Send2Trash in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (1.5.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (20.0.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (0.9.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (2.11.3)\n",
      "Requirement already satisfied: ptyprocess in /opt/conda/lib/python3.7/site-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (0.7.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from cvxpy->pymgrid==0.1.0) (1.4.1)\n",
      "Requirement already satisfied: ecos>=2 in /opt/conda/lib/python3.7/site-packages (from cvxpy->pymgrid==0.1.0) (2.0.7.post1)\n",
      "Requirement already satisfied: osqp>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from cvxpy->pymgrid==0.1.0) (0.6.2.post0)\n",
      "Requirement already satisfied: scs>=1.1.6 in /opt/conda/lib/python3.7/site-packages (from cvxpy->pymgrid==0.1.0) (2.1.2)\n",
      "Requirement already satisfied: qdldl in /opt/conda/lib/python3.7/site-packages (from osqp>=0.4.1->cvxpy->pymgrid==0.1.0) (0.1.5.post0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from gym->pymgrid==0.1.0) (1.5.0)\n",
      "Requirement already satisfied: Pillow<=7.2.0 in /opt/conda/lib/python3.7/site-packages (from gym->pymgrid==0.1.0) (7.2.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from gym->pymgrid==0.1.0) (1.4.1)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from pyglet<=1.5.0,>=1.4.0->gym->pymgrid==0.1.0) (0.18.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (3.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (1.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pymgrid==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pymgrid==0.1.0) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pymgrid==0.1.0) (2.4.7)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (0.1.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (0.3)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (0.4.4)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (0.6.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (1.4.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (0.8.4)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (0.5.3)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (3.3.0)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.7/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (1.5.1)\n",
      "Requirement already satisfied: async-generator in /opt/conda/lib/python3.7/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (1.10)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (20.9)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->pymgrid==0.1.0) (0.5.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->pymgrid==0.1.0) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->pymgrid==0.1.0) (1.25.11)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->pymgrid==0.1.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->pymgrid==0.1.0) (2.10)\n",
      "Requirement already satisfied: patsy>=0.5 in /opt/conda/lib/python3.7/site-packages (from statsmodels->pymgrid==0.1.0) (0.5.1)\n",
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.18.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "# Install pymgrid\n",
    "!pip install git+https://github.com/Total-RD/pymgrid/\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqChWIKtZALb"
   },
   "source": [
    "# Nouvelle section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iYsDtDts0XxA"
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import time # Necessary to evaluate frugality\n",
    "import json # Necessary to export your results\n",
    "import pickle # Necessary to load the data\n",
    "import DiscreteEnvironment as DiscreteEnvironment # Imposed Discrete Environment\n",
    "from pymgrid.Environments.pymgrid_cspla import MicroGridEnv # Imposed Environment\n",
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JowPXJENcwqp"
   },
   "outputs": [],
   "source": [
    "# Open data\n",
    "\n",
    "with open('building_1.pkl', 'rb') as f:\n",
    "    building_1 = pickle.load(f)\n",
    "    building_1.train_test_split()\n",
    "\n",
    "with open('building_2.pkl', 'rb') as f:\n",
    "    building_2 = pickle.load(f)\n",
    "    building_2.train_test_split()\n",
    "\n",
    "with open('building_3.pkl', 'rb') as f:\n",
    "    building_3 = pickle.load(f)\n",
    "    building_3.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "HLpQNcT6HVna"
   },
   "outputs": [],
   "source": [
    "# Group building\n",
    "buildings = [building_1, building_2, building_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZA3jYA3pA3qz"
   },
   "outputs": [],
   "source": [
    "# Global hyperparameters\n",
    "def make_hyperparameters(C = 5,\n",
    "                         alpha = None,\n",
    "                         omega = 0.7,\n",
    "                         discount_factor = 0.99,\n",
    "                         epsilon = 0.99,\n",
    "                         epsilon_min = 0.1,\n",
    "                         epsilon_decay = 0.02,\n",
    "                         epsilon_expo = False,\n",
    "                         train_days = 4,\n",
    "                         train_episodes = 200,\n",
    "                         train_episodes_decay = 30,\n",
    "                         max_steps = 24):\n",
    "  return {\n",
    "          \"C\" : C,\n",
    "          \"alpha\" : alpha,\n",
    "          \"omega\" : omega,\n",
    "          \"discount_factor\" : discount_factor,\n",
    "          \"epsilon\" : epsilon,\n",
    "          \"epsilon_min\" : epsilon_min,\n",
    "          \"epsilon_decay\" : epsilon_decay,\n",
    "          \"epsilon_expo\" : epsilon_expo,\n",
    "          \"train_days\" : train_days,\n",
    "          \"train_episodes\" : train_episodes,\n",
    "          \"train_episodes_decay\" : train_episodes_decay,\n",
    "          \"max_steps\" : max_steps\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FYHpOc4DJ-Os"
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "def test(env, QA, QB, testing=False):\n",
    "    state = env.reset(testing=testing)\n",
    "    done = False\n",
    "    total_cost = 0\n",
    "    while not done:\n",
    "        actionA = np.argmax(QA[state])\n",
    "        actionB = np.argmax(QB[state])\n",
    "        if QA[state][actionA] > QB[state][actionB]:\n",
    "            action = actionA\n",
    "        else:\n",
    "            action = actionB\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        total_cost += reward\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0yFexh4SJEdW"
   },
   "outputs": [],
   "source": [
    "# Test ML model\n",
    "def test_ml(env, clf, testing=False):\n",
    "    state = env.reset(testing=testing)\n",
    "    done = False\n",
    "    total_cost = 0\n",
    "    while not done:\n",
    "        action = clf.predict(np.array(state).reshape(1, 2))\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        total_cost += reward\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "atD-m5DBDxGC"
   },
   "outputs": [],
   "source": [
    "# Training the agent\n",
    "\n",
    "def train(p, env, debug=False):\n",
    "\n",
    "    # Display the state space\n",
    "    if debug:\n",
    "        print(\"Action Space {}\".format(env.action_space))\n",
    "        print(\"State Space {}\".format(env.observation_space))\n",
    "\n",
    "    # Intialize the Q table\n",
    "    QA, QB = {}, {}\n",
    "\n",
    "    # Reset discoveries\n",
    "    QA_count, QB_count = {}, {}\n",
    "\n",
    "    # Use the first reward to initialize\n",
    "    C = p[\"C\"]\n",
    "\n",
    "    # Initialize epsilon and alpha\n",
    "    epsilon = p[\"epsilon\"]\n",
    "\n",
    "    # Custom alpha decay (https://www.jmlr.org/papers/volume5/evendar03a/evendar03a.pdf)\n",
    "    \"\"\"def get_alpha(s,a):\n",
    "        if (s in Q_count) and (Q_count[s][a] > 0):\n",
    "            return 1.0 / np.power(Q_count[s][a], p[\"omega\"])\n",
    "        else:\n",
    "            return 0.0\"\"\"\n",
    "    \n",
    "    def get_alpha(s,a, Q_count):\n",
    "        if (s in Q_count) and (Q_count[s][a] > 0):\n",
    "            return 1.0 / np.power(Q_count[s][a], p[\"omega\"])\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "    # Train on different days\n",
    "    training_rewards = []\n",
    "\n",
    "    train_episodes = p[\"train_episodes\"]\n",
    "    for day in range(p[\"train_days\"]):\n",
    "        # print(\"Day {}/{}\".format(day+1,p[\"train_days\"]))\n",
    "\n",
    "        # Creating lists to keep track of reward and epsilon values\n",
    "        day_training_rewards = []\n",
    "\n",
    "        for episode in range(train_episodes):\n",
    "            # print(\"Episode {}/{}\".format(episode+1,train_episodes))\n",
    "\n",
    "            #Reseting the environment each time as per requirement\n",
    "            state = tuple(env.reset())\n",
    "            if not (state in QA):\n",
    "                QA[state] = [C for i in range(env.Na)]\n",
    "                QB[state] = [C for i in range(env.Na)]\n",
    "            if not (state in QA_count):\n",
    "                QA_count[state] = [0 for i in range(env.Na)]\n",
    "                QB_count[state] = [0 for i in range(env.Na)]\n",
    "\n",
    "            # Starting the tracker for the rewards\n",
    "            total_training_rewards = 0\n",
    "\n",
    "            # Choosing an action given the states based on a random number\n",
    "            exp_exp_tradeoff = np.random.random()\n",
    "\n",
    "            ### STEP 2: SECOND option for choosing the initial action - exploit\n",
    "            # If the random number is larger than epsilon: employing exploitation\n",
    "            # and selecting best action\n",
    "            if exp_exp_tradeoff < (1 - epsilon):\n",
    "                actionA = np.argmax(QA[state])\n",
    "                actionB = np.argmax(QB[state])\n",
    "                if QA[state][actionA] > QB[state][actionB]:\n",
    "                    action = actionA\n",
    "                else:\n",
    "                    action = actionB\n",
    "            ### STEP 2: FIRST option for choosing the initial action - explore\n",
    "            # Otherwise, employing exploration: choosing a random action\n",
    "            else:\n",
    "                action = np.random.choice(env.Na) # env.action_space.sample()\n",
    "\n",
    "            for step in range(p[\"max_steps\"]):\n",
    "\n",
    "                ### STEPs 3 & 4: performing the action and getting the reward\n",
    "                # Taking the action and getting the reward and outcome state\n",
    "                new_state, reward, done, info = env.step(action)\n",
    "                new_state = tuple(new_state)\n",
    "\n",
    "                ### STEP 5: update the Q-table\n",
    "\n",
    "                # Check if values are in the table\n",
    "                if not (state in QA):\n",
    "                    QA[state] = [C for i in range(env.Na)]\n",
    "                    QB[state] = [C for i in range(env.Na)]\n",
    "                if not (state in QA_count):\n",
    "                    QA_count[state] = [0 for i in range(env.Na)]\n",
    "                    QB_count[state] = [0 for i in range(env.Na)]\n",
    "                if not (new_state in QA):\n",
    "                    QA[new_state] = [C for i in range(env.Na)]\n",
    "                    QB[new_state] = [C for i in range(env.Na)]\n",
    "\n",
    "                # Set dynamic alpha\n",
    "                if p[\"alpha\"]:\n",
    "                    alpha = p[\"alpha\"]\n",
    "\n",
    "                # 50% chance to update QA (or QB)\n",
    "                choice = np.random.random()\n",
    "\n",
    "                # Updating Q's\n",
    "                if choice >= 0.5:\n",
    "                    new_action = np.argmax(QA[new_state])\n",
    "\n",
    "                    if not p[\"alpha\"]:\n",
    "                        alpha = get_alpha(new_state, action, QA_count)\n",
    "\n",
    "                    # Updating the Q-table using the Bellman equation\n",
    "                    if step == p[\"max_steps\"] - 1:\n",
    "                        QA[state][action] += alpha * (reward - QA[state][action])\n",
    "                    else:\n",
    "                        QA[state][action] = (1 - alpha) * QA[state][action] + alpha * (reward + p[\"discount_factor\"] * QA[new_state][new_action] - QA[state][action])\n",
    "                    QA_count[state][action] += 1\n",
    "                  \n",
    "                elif choice < 0.5:\n",
    "                    new_action = np.argmax(QB[new_state])\n",
    "\n",
    "                    if not p[\"alpha\"]:\n",
    "                        alpha = get_alpha(new_state, action, QB_count)\n",
    "\n",
    "                    # Updating the Q-table using the Bellman equation\n",
    "                    if step == p[\"max_steps\"] - 1:\n",
    "                        QB[state][action] += alpha * (reward - QB[state][action])\n",
    "                    else:\n",
    "                        QB[state][action] = (1 - alpha) * QB[state][action] + alpha * (reward + p[\"discount_factor\"] * QB[new_state][new_action] - QB[state][action])\n",
    "                    QB_count[state][action] += 1\n",
    "\n",
    "                # Increasing our total reward and updating the state\n",
    "                total_training_rewards -= reward\n",
    "                state = new_state\n",
    "                action = new_action\n",
    "\n",
    "                # Ending the episode\n",
    "                if done == True:\n",
    "                    if debug:\n",
    "                        print (\"Total reward for episode {}: {}\".format(episode, total_training_rewards))\n",
    "                    break\n",
    "\n",
    "            # Cutting down on exploration by reducing the epsilon\n",
    "            if p[\"epsilon_expo\"]:\n",
    "              epsilon = p[\"epsilon_min\"] + (p[\"epsilon\"] - p[\"epsilon_min\"]) * np.exp(-p[\"epsilon_decay\"] * episode)\n",
    "            else:\n",
    "              epsilon = max(p[\"epsilon_min\"], epsilon - epsilon * p[\"epsilon_decay\"])\n",
    "\n",
    "            # Adding the total reward and reduced epsilon values\n",
    "            day_training_rewards.append(total_training_rewards)\n",
    "\n",
    "        # Decrease the number of steps\n",
    "        train_episodes -= p[\"train_episodes_decay\"]\n",
    "        training_rewards += day_training_rewards\n",
    "\n",
    "        if debug:\n",
    "            print (\"Training score over time (Day {}): \".format(day) + str(sum(training_rewards)/train_episodes))\n",
    "\n",
    "    return training_rewards, QA, QB, QA_count, QB_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jHBXLyjEJXTH"
   },
   "outputs": [],
   "source": [
    "# Build a decision tree\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "\n",
    "def build_clf(p, QA, QB, QA_count, QB_count):\n",
    "\n",
    "  # Build dataset\n",
    "  X = []\n",
    "  y = []\n",
    "  for s in QA.keys():\n",
    "    actionA = np.argmax(QA[s])\n",
    "    actionB = np.argmax(QB[s])\n",
    "\n",
    "    # Choose the best action\n",
    "    if QA[s][actionA] > QB[s][actionB]:\n",
    "        action, orig = actionA, 1\n",
    "    elif QA[s][actionA] < QB[s][actionB]:\n",
    "        action, orig = actionB, 0\n",
    "    else:\n",
    "        action, orig = random.choice([(actionA,1), (actionB,0)])\n",
    "\n",
    "    # If unitialized, choose the another\n",
    "    if (orig == 1) and not ((s in QA_count and QA_count[s][action] > 0) or (QA[s][action] != p['C'])):\n",
    "        action, orig = actionB, 0\n",
    "    elif (orig == 0) and not ((s in QB_count and QB_count[s][action] > 0) or (QB[s][action] != p['C'])):\n",
    "        action, orig = actionA, 1    \n",
    "\n",
    "    # Append to dataset\n",
    "    if (orig == 1) and ((s in QA_count and QA_count[s][action] > 0) or (QA[s][action] != p['C'])):\n",
    "      y.append(action)\n",
    "      X.append(np.array(s))\n",
    "    if (orig == 0) and ((s in QB_count and QB_count[s][action] > 0) or (QB[s][action] != p['C'])):\n",
    "      y.append(action)\n",
    "      X.append(np.array(s))\n",
    "\n",
    "  # Build and train model\n",
    "  clf = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "  clf.fit(X, y)\n",
    "\n",
    "  return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "U_T0U5VzLurM"
   },
   "outputs": [],
   "source": [
    "# Full benchmark\n",
    "import time\n",
    "\n",
    "def benchmark(p):\n",
    "  building_environments = [DiscreteEnvironment.Environment(env_config={'building':buildings[i]}) for i in range(3)]\n",
    "\n",
    "  # Train on the first building\n",
    "  clfs = [None, None, None]\n",
    "  train_start = time.process_time()\n",
    "  for i,building_env in enumerate(building_environments):\n",
    "    training_rewards, QA, QB, QA_count, QB_count = train(p, building_env)\n",
    "    clfs[i] = build_clf(p, QA, QB, QA_count, QB_count)\n",
    "  train_end = time.process_time()\n",
    "\n",
    "  # Test our model on train data\n",
    "  scores_train = [0,0,0]\n",
    "  for i,building_env in enumerate(building_environments):\n",
    "    scores_train[i] = -1 * test_ml(building_env, clfs[i], testing=False)\n",
    "\n",
    "  # Test our model on test data\n",
    "  scores_test = [0,0,0]\n",
    "  test_start = time.process_time()\n",
    "  for i,building_env in enumerate(building_environments):\n",
    "    scores_test[i] = -1 * test_ml(building_env, clfs[i], testing=True)\n",
    "  test_end = time.process_time()\n",
    "\n",
    "  # Usefull quantities\n",
    "  train_frugality = train_end - train_start\n",
    "  test_frugality = test_end - test_start\n",
    "  frugality = train_frugality + test_frugality\n",
    "  total_cost = scores_test\n",
    "\n",
    "  # Make results\n",
    "  final_results = {\n",
    "      \"building_1_performance\" : total_cost[0],\n",
    "      \"building_2_performance\" : total_cost[1],\n",
    "      \"building_3_performance\" : total_cost[2],\n",
    "      \"frugality\" : frugality,\n",
    "  }\n",
    "\n",
    "  return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark our model\n",
    "\n",
    "best_param = {\n",
    "     'C': 5,\n",
    "     'alpha': 0.22631578947368422,\n",
    "     'discount_factor': 1.0,\n",
    "     'epsilon': 0.99,\n",
    "     'epsilon_decay': 4.894736842105263,\n",
    "     'epsilon_expo': True,\n",
    "     'epsilon_min': 0.1,\n",
    "     'max_steps': 24,\n",
    "     'omega': 0.7289473684210527,\n",
    "     'train_days': 1,\n",
    "     'train_episodes': 30,\n",
    "     'train_episodes_decay': 30\n",
    "}\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "final_results = benchmark(best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to JSON\n",
    "with open('corai.txt', 'w') as json_file:\n",
    "    json.dump(final_results, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'building_1_performance': 4089.2658357035007,\n",
      " 'building_2_performance': 13630.886119011686,\n",
      " 'building_3_performance': 16741.597568815654,\n",
      " 'frugality': 5.1903507069999995}\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "import pprint\n",
    "\n",
    "pprint.pprint(final_results)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Notebook - Louis - DoubleQL - Hyperparam.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
